#!/usr/bin/env perl

=pod

=head1 NAME

uniproc - Universal data processing tool

=head1 SYNOPSIS

uniproc [I<OPTIONS>] I<INPUTFILE> I<COMMAND> [I<ARGS>]

=head1 DESCRIPTION

Take each line from I<INPUTFILE> as B<DATA> (chopping end-of-line chars),
pass each TAB-delimited fields of B<DATA> to I<COMMAND> as arguments after I<ARGS>
(unless placeholder is in I<COMMAND> or I<ARGS>, see below),
run I<COMMAND> and then record the exit status.

Can be parallelized well.
uniproc(1) itself does not run multiple instances of I<COMMAND> in parallel, just in series,
but if you start multiple instances of uniproc(1), then you can run I<COMMAND>s concurrently.
Locking ensures no overlapping data being processed.
So you don't need special precautions (locking, data partitioning) when starting uniproc(1) multiple times on the same I<INPUTFILE>.

Use a wrapper command/script for I<COMMAND> if you want either of these:

=over 4

=item save I<COMMAND>'s output as well.

By default it goes to STDOUT.
Use redirexec(1) for example.

=item pass B<DATA> on the STDIN or in environment variable instead of command argument.

Use args2env(1) or args2stdin(1) for example.

=back

If re-run after an interrupt, won't process already processed data.
But you may re-try the failed ones by the B<--retry> option.

The user is allowed to append new lines of data to I<INPUTFILE> between executions or during runtime - it won't mess up the processing.
However editing or reordering lines which are already in the file, confuses the results - don't do it.

I<ARGS> (and I<COMMAND> too, somewhat usefully) supports placeholders:
A curly bracket-pair C<{}> is replaced to B<DATA> as one argument, including TAB chars if any, anywhere in I<COMMAND> I<ARGS>.
If there is a number in it, B<{>I<N>B<}>, then the I<N>th TAB-delimited field (1-indexed) is gonna be substituted in.
A lone B<{@}> argument expands to as many arguments as TAB-delimited fields there are in B<DATA>.
Multiple numbers in the placeholder like B<{5,3,4}> expands to all of the data fields specified by the index numbers, into multiple arguments.
Note that in this case, the multi-index placeholder must stand in its own separate argument, just as the all-fields B<{@}> placeholder.
Indexing a non-existing field expands to empty string.
Be aware that your shell (eg. bash(1)) may expand arguments like C<{5,3,4}> before it gets to uniproc(1),
so escape it if neccessary (eg. C<'{5,3,4}'>).
If there is any curly bracket placeholder like these, B<DATA> fields won't be added to I<ARGS> as the last argument.

=head1 OPTIONS

=over 4

=item -r, --retry

Process those data which were earlier failed (according to B<< I<INPUTFILE>.uniproc >> state file) too,
besides the unprocessed ones.

=item -f, --failed

Process only the earlier failed items.

=item -1, --one-item

Process only 1 item, then exit.
Default is to process as many items in series as possible.

=item -n, --items I<NUM>

How many items to process.

=item -e, --errexit

Stop processing items as soon as the first I<COMMAND> exits non-zero,
and uniproc(1) itself exists which that exit code (or 128+signal if signaled).

=item -Q, --quasilock

Create and check locks using lock files instead of flock(2).
Useful for network filesystems which does not support shared locks (eg. sshfs).
It is assumed that either all instances of uniproc(1),
across all hosts that are working on a given I<INPUTFILE>,
are run in quasi-lock mode, or all in flock(2)-lock mode - do not mix.
These quasi lock files are:

=over 4

=item I<INPUTFILE>.uniproc.lock

locking the I<INPUTFILE>.uniproc state file, and

=item I<INPUTFILE>.uniproc.I<NUM>

locking the command processing the I<NUM>th item.
Note, this is the same file which is locked by flock(2) in real-lock mode.

=back

Beware, when using quasi-locks: the user may manually clean up lock files
which are left there after an interrupted process.
While atomic lock acquisition is approximated using general filesystem primitives,
there is no simple race-free to automatically release the lock when a process terminates.
Therefore uniproc(1) does not even try to emulate such lock-release mechanism,
so it neither detects nor reclaims stale lock files.
However to help the user identify possibly alive processes which expect resources being exclusively allocated to them,
uniproc(1) writes some useful info about the current process in the lock files:
B<PID> B<START_TIMESTAMP> B<HOSTNAME>.

=item -sp, --show-progress

Show which item is being started to process.

=item -sd, --show-data

Show the raw data what is being started to process.

=item -ss, --show-summary

Show stats summary when exit.

=item --debug

Output debug messages.

=back

=head1 FILES

It maintains I<INPUTFILE>.uniproc file
by writing the processing status of each lines of input data in it line-by-line.
Processing status is either:

=over 4

=item all spaces (C<   >)

processing not yet started

=item periods (C<...>)

in progress

=item digits, possibly padded by spaces (C<  0>)

result status (exit code)

=item exclamation mark (C<!>) followed by hexadecimal digits (C<!0f>)

termination signal (I<COMMAND> teminated abnormally)

=item EOF (ie. fewer lines than input data)

processing of this item has not started yet

=back

I<INPUTFILE>.uniproc is locked while read/write to ensure consistency.
I<INPUTFILE>.uniproc.B<NUM> are the name of the files which hold the lock for the currently in-progress processes,
where B<NUM> is the line number of the corresponding piece of data in I<INPUTFILE>.
A lock is held on each of these I<INPUTFILE>.proc.B<NUM> files by the respective instance of I<COMMAND>
to detect if the processing is still going or the process crashed.

=head1 LIMITATION

Due to currently used locking mechanism (Fcntl(3perl)), running on multiple hosts may disrespect locking,
depending on the network filesystem. See B<--quasilock> option.

=head1 ENVIRONMENT

When running I<COMMAND>, the following environment is set:

=over 4

=item UNIPROC_DATANUM

Number of the particular piece of data (ie. line number in I<INPUTFILE>, 0-indexed)
which is need to be processed by the current process.

=item UNIPROC_DATANUM_1INDEX

Same as B<UNIPROC_DATANUM> but 1-indexed instead of 0-indexed.

=item UNIPROC_TOTALNUM

Total number of items (processed and unprocessed).
Note this figure may be outdated
because I<INPUTFILE> is not always measured before each I<COMMAND> start.

=back

=head1 EXAMPLES

Display the data processing status before each line of data:

  paste datafile.uniproc datafile

How much competed?

  awk -v total=$(wc -l < datafile) 'BEGIN{ok=ip=fail=0} {if($1==0){ok++} else if($1=="..."){ip++} else if($1!=""){fail++}} END{print "total: "total", completed: "ok" ("(ok*100/total)"%), in-progress: "ip" ("(ip*100/total)"%), failed: "fail" ("(fail*100/total)"%)"}' datafile.uniproc
  
Output:

  total: 8, completed: 4 (50%), in-progress: 1 (12.5%), failed: 1 (12.5%)

Record output of data processing into a file per each data item:

  uniproc datafile sh -c 'some-command "$@" | tee output-$UNIPROC_DATANUM' --

  uniproc datafile substenv -e UNIPROC_DATANUM redirexec '1:a:file:output-$UNIPROC_DATANUM' some-command

Same as above, plus keep the output on STDOUT as well as in separate files.
Note, the C<{}> argument is there to pass B<DATA> to the right command:

  uniproc datafile pipecmd some-command {} -- substenv -e UNIPROC_DATANUM tee -a 'output-$UNIPROC_DATANUM'

Display data number, processing status, input data, (last line of) output data in a table:

  join -t $'\t' <(nl -ba -v0 datafile.uniproc) <(nl -ba -v0 datafile) | foreach -t --prefix-add-data --prefix-add-tab tail -n1 output-{0}

=cut


use Fcntl qw/:flock :seek O_EXCL O_RDWR O_CREAT/;
use Data::Dumper;
use Getopt::Long qw/:config no_ignore_case no_bundling no_getopt_compat no_auto_abbrev require_order/;
use IPC::Run qw/run/;
use POSIX qw/:sys_wait_h pause raise/;
use Pod::Usage;
use Time::HiRes qw/sleep/;
use Sys::Hostname qw/hostname/;
use File::stat;

$OptProcessNew = 1;
$OptProcessFailed = 0;
$OptShots = undef;
$OptShowProgress = 0;
$OptShowData = 0;
$OptShowSummary = 0;
$OptDebug = 0;
$OptErrExit = 0;
$OptQuasiLock = 0;

GetOptions(
	'r|retry' => sub { $OptProcessFailed = 1; $OptProcessNew = 1; },
	'f|failed' => sub { $OptProcessFailed = 1; $OptProcessNew = 0; },
	'1|oneshot|one-item' => sub { $OptShots = 1; },
	'n|items=i' => \$OptShots,
	'sp|show-progress' => \$OptShowProgress,
	'sd|show-data' => \$OptShowData,
	'ss|show-summary' => \$OptShowSummary,
	'Q|quasilock!' => \$OptQuasiLock,
	'e|errexit!' => \$OptErrExit,
	'debug!' => \$OptDebug,
	'help' => sub { pod2usage(-exitval=>0, -verbose=>99); },
) or pod2usage(-exitval=>2, -verbose=>99);

die "$0: missing command\n" unless scalar @ARGV >= 2;


$PROCESS_START_TIMESTAMP = stat("/proc/$$")->ctime;
$SYSTEM_NAME = hostname();


sub debug_msg
{
	warn @_ if $OptDebug;
}

sub deriv_processing_status
{
	my $child_status = shift;
	my $status = sprintf '%3d', WEXITSTATUS($child_status);
	$status = sprintf '!%02x', WTERMSIG($child_status) if WIFSIGNALED($child_status);
	return $status;
}

sub fopen
{
	my $path = shift;
	my $opts = shift;  # supported opts: rw, no_create, lock, quasilockfile
	$opts->{'quasilockfile'} ||= "$path.lock";
	my $lock_acquired;
	
	# in quasi-lock mode the lock file needs to be checked/opened first.
	if($opts->{'lock'} and $OptQuasiLock)
	{
		if($path eq $opts->{'quasilockfile'} and $opts->{'no_create'})
		{
			die "$0: fopen() 'no_create' option is not supported in quasi-lock mode when the lock file is the same as the file to be opened ($path).\n";
		}
		
		my $lock_fh;
		while(1)
		{
			my $open_ok = sysopen($lock_fh, $opts->{'quasilockfile'}, O_RDWR|O_CREAT|O_EXCL);
			if($open_ok)
			{
				print {$lock_fh} "$$ $PROCESS_START_TIMESTAMP $SYSTEM_NAME";
				$lock_acquired = 1;
				last;
			}
			last if not $opts->{'waitlock'};
			sleep rand;
		}
		close $flock_fh if defined $flock_fh;
		
		if(not $lock_acquired)
		{
			return undef;
		}
	}
	
	my $mode = '<';  # default mode is read-only, no-create
	if($opts->{'rw'})
	{
		if(not $opts->{'no_create'})
		{
			# in quasilock mode, it is likely already created, but nevermind, there are more sub-optimal behavior in that mode than this.
			open my $fh, '>>', $path or die "$0: $path: $!\n";
			close $fh;
		}
		$mode = '+<';
	}
	
	open my $fh, $mode, $path or die "$0: $path: $!\n";
	seek $fh, 0, SEEK_SET or die "$0: seek: $path: $!\n";
	
	if($opts->{'lock'} and not $OptQuasiLock)
	{
		my $lock_mode = LOCK_EX;
		$lock_mode |= LOCK_NB if not $opts->{'waitlock'};
		$lock_acquired = flock $fh, $lock_mode or die "$0: flock: $path: $!\n";
		
		if(not $lock_acquired)
		{
			close $fh;
			return undef;
		}
	}
	return $fh;
}

sub extend_resultsfile
{
	my $fname = $ResultsFile;
	my $fh = shift;
	my $extended_size = shift;
	
	seek $fh, 0, SEEK_END;
	my $size = tell $fh;
	my $endpos_last_complete_record = int($size / $ResultsRecordLength) * $ResultsRecordLength;
	my $records_to_append = ($extended_size - $endpos_last_complete_record) / $ResultsRecordLength;
	debug_msg "go to offset $endpos_last_complete_record to extend by $records_to_append records\n";
	seek $fh, $size, SEEK_SET;
	# fill up with empty status records
	print {$Results_fh} "   \n" x $records_to_append or die "$0: write: $fname: $!\n";
}

sub record_status
{
	my $linenum = shift;
	my $status = shift;
	die "$0: size mismatch: length(\"$status\") != $ResultsRecordLength - 1\n" if length($status) != $ResultsRecordLength - 1;
	
	my $offset = $linenum * $ResultsRecordLength;
	debug_msg "go to offset $offset to record data # $linenum 's status \"$status\"\n";
	seek $Results_fh, $offset, SEEK_SET;
	if(eof $Results_fh)
	{
		debug_msg "eof\n";
		# results file is not big enough, let's extend
		extend_resultsfile($Results_fh, $offset);
		seek $Results_fh, $offset, SEEK_SET;
	}
	print {$Results_fh} "$status\n" or die "$0: write: $ResultsFile: $!\n";
}

sub input_data
{
	# TODO use index file, if exists, to seek in.
	
	my $asked_line = shift;
	my $fh = fopen $InputFile, {no_create=>1,};
	my $linenum = 0;
	my $data = undef;
	while(my $line = <$fh>)
	{
		if($linenum == $asked_line)
		{
			$data = $line;
			chomp $data;
			last;
		}
		$linenum++;
	}
	close $fh;
	return $data;
}

sub count_input_records
{
	# TODO use index file, if exists.
	
	my $fh = fopen $InputFile, {no_create=>1,};
	my $linenum = 0;
	$linenum++ while scalar <$fh>;
	close $fh;
	$TotalDataNum = $linenum;
	return $linenum;
}

sub processing_lockfile_name
{
	my $processing_number = shift;
	return "$InputFile.uniproc.$processing_number";
}

sub still_in_progress
{
	my $processing_number = shift;
	my $lockfile = processing_lockfile_name($processing_number);
	open my $fh, '<', $lockfile or return 0;
	my $lockable;
	if($OptQuasiLock)
	{
		# if the lock file is there, assuming it is alive.
		$lockable = 0;
	}
	else
	{
		$lockable = flock $fh, LOCK_EX|LOCK_NB;
	}
	close $fh;
	return not $lockable;
}

sub get_next_data_number
{
	debug_msg "go to offset ".($FirstUnprocessedRecord*$ResultsRecordLength)." to read status of record # $FirstUnprocessedRecord\n";
	seek $Results_fh, $FirstUnprocessedRecord*$ResultsRecordLength, SEEK_SET;
	
	my $record_num = $FirstUnprocessedRecord;
	my $result;
	while(1)
	{
		my $nbytes = read $Results_fh, $result, $ResultsRecordLength;
		debug_msg "read only $nbytes bytes \"$result\" at record $record_num\n" if $nbytes < $ResultsRecordLength;
		last if $nbytes < $ResultsRecordLength;
		chomp $result;
		
		if($result eq '   ' and $OptProcessNew)
		{
			$FirstUnprocessedRecord = $record_num+1;
			debug_msg "uninitialized $record_num\n";
			return $record_num;
		}
		if($result eq '...' and $OptProcessNew)
		{
			# check if still locked
			if(not still_in_progress($record_num))
			{
				$FirstUnprocessedRecord = $record_num+1;
				debug_msg "crashed $record_num\n";
				return $record_num;
			}
		}
		if($OptProcessFailed and ($result =~ /^!/ or ($result =~ /^\s*\d+$/ and $result > 0)))
		{
			$FirstUnprocessedRecord = $record_num+1;
			debug_msg "retry $record_num\n";
			return $record_num;
		}
		
		$record_num++;
	}
	
	return undef if not $OptProcessNew;
	
	# check here if there are more input data than result records
	my $input_records = count_input_records();
	if($record_num < $input_records)
	{
		extend_resultsfile($Results_fh, $input_records * $ResultsRecordLength);
		$FirstUnprocessedRecord = $record_num+1;
		debug_msg "new $record_num\n";
		return $record_num;
	}
	
	# no more input data
	debug_msg "no more input. input_records=$input_records\n";
	return undef;
}

sub subst_data
{
	my $data = shift;
	my $field_num = shift;
	my $fields = shift;
	if($field_num =~ /^\d+$/)
	{
		return $fields->[$field_num-1];
	}
	return $data;
}

sub expand_placeholders
{
	my $arg = shift;
	my $Data = shift;
	my $DataFields_ref = shift;
	my $placeholder_found_ref = shift;
	
	if($arg =~ s/\{(\d*)\}/subst_data($Data, $1, $DataFields_ref)/eg)
	{
		$$placeholder_found_ref = 1;
		return $arg;
	}
	if(my ($indices) = $arg =~ /^\{([\d,]+|\@)\}$/)
	{
		$$placeholder_found_ref = 1;
		return @$DataFields_ref if $indices eq '@';
		return map {$DataFields_ref->[$_-1] // ''} split /,/, $indices;
	}
	return $arg;
}


($InputFile, @CommandArgs) = @ARGV;

$FirstUnprocessedRecord = 0;
$ResultsRecordLength = 4;
$ResultsFile = "$InputFile.uniproc";
$Results_fh = undef;
$num_shots = 0;
$TotalDataNum = undef;
$ExitStatus = 0;
$TermSignal = undef;
$InputFileQuasiLockFile = undef;


sub cleanup_quasi_locks
{
	unlink $ResultsFile_QuasiLockFile if defined $ResultsFile_QuasiLockFile;
}

sub signal_handler
{
	my $signame = shift;
	$SIG{INT} = $SIG{TERM} = $SIG{QUIT} = undef;  # set default signal handler
	cleanup_quasi_locks();
	$TermSignal = $signame;
	die "\n";
}

$SIG{INT} = \&signal_handler;
$SIG{TERM} = \&signal_handler;
$SIG{QUIT} = \&signal_handler;
END { cleanup_quasi_locks(); }


if(not eval {
	while(not defined $OptShots or $num_shots < $OptShots)
	{
		$Results_fh = fopen $ResultsFile, {rw=>1, lock=>1, quasilockfile=>"$ResultsFile.lock", waitlock=>1};
		$ResultsFile_QuasiLockFile = "$ResultsFile.lock";
		
		my $LineNum = get_next_data_number();
		last if not defined $LineNum;
		count_input_records if not defined $TotalDataNum;
		
		my $Data = input_data($LineNum);
		my @DataFields = split /\t/, $Data;
		
		my $InprogressFile = processing_lockfile_name($LineNum);
		my $inprogress_fh = fopen $InprogressFile, {rw=>1, lock=>1, quasilockfile=>$InprogressFile, waitlock=>0};
		
		if(defined $inprogress_fh)
		{
			record_status($LineNum, '...');
		}
		
		close $Results_fh; unlink $ResultsFile_QuasiLockFile; $ResultsFile_QuasiLockFile = undef;
		
		if(not defined $inprogress_fh)
		{
			debug_msg "could not open/lock '$InprogressFile'\n";
			next;
		}
		
		printf STDERR "uniproc: %d/%d%s%s\n", $LineNum+1, $TotalDataNum, ($OptShowData ? (": ", $Data) : ("", "")) if $OptShowProgress;
		
		$ENV{'UNIPROC_DATANUM'} = $LineNum;
		$ENV{'UNIPROC_DATANUM_1INDEX'} = $LineNum+1;
		$ENV{'UNIPROC_TOTALNUM'} = $TotalDataNum;
		
		my $placeholder_found = 0;
		my @command_args = map {expand_placeholders($_, $Data, \@DataFields, \$placeholder_found)} @CommandArgs;
		if(not $placeholder_found)
		{
			push @command_args, @DataFields;
		}
		
		my $stdin = '';
		run [@command_args], \$stdin, init => sub {
			print {$inprogress_fh} join(' ', $$, stat("/proc/$$")->ctime, $SYSTEM_NAME) if $OptQuasiLock;
		};
		my $status = $?;
		
		$Results_fh = fopen $ResultsFile, {rw=>1, lock=>1, quasilockfile=>"$ResultsFile.lock", waitlock=>1};
		$ResultsFile_QuasiLockFile = "$ResultsFile.lock";
		record_status($LineNum, deriv_processing_status($status));
		close $Results_fh; unlink $ResultsFile_QuasiLockFile; $ResultsFile_QuasiLockFile = undef;
		
		if(WIFSIGNALED($status) or WEXITSTATUS($status)) { $CountFailed++; }
		else { $CountSuccess++; }
		
		close $inprogress_fh;
		unlink $InprogressFile;  # it is the lockfile of itself in quasilock mode.
		
		if($OptErrExit)
		{
			$ExitStatus = WIFSIGNALED($status) ? 128 + WTERMSIG($status) : WEXITSTATUS($status);
			last;
		}
		
		$num_shots++;
	}
	
	if($OptShowSummary)
	{
		printf STDERR "uniproc: %d total, %d processed in this session, %d successful, %d failed\n", $TotalDataNum, $CountSuccess+$CountFailed, $CountSuccess, $CountFailed;
	}
	1;
})
{
	warn $@ if $@ ne "\n";
	$ExitStatus = -1;
}

if(defined $TermSignal)
{
	kill $TermSignal, $$;
}
else
{
	exit $ExitStatus;
}
